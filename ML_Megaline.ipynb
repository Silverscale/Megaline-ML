{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9990596e",
   "metadata": {},
   "source": [
    "# Megaline plan recomendator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1e486",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Data Loading and Inspection](#data-loading-and-inspection)\n",
    "3. [Model training](#model-training)\n",
    "    1. [Splitting the data into sets](#splitting-the-data-into-sets)\n",
    "    2. [Decision Tree model](#decision-tree-model)\n",
    "    3. [Random Forest model](#random-forest-model)\n",
    "    4. [Logistic Regression model](#logistic-regression-model)\n",
    "    5. [Quality check using the test set](#quality-check-using-the-test-set)\n",
    "    6. [Sanity check](#sanity-check)\n",
    "4. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da9356",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the project for the \"Intro into Machine Learning\" sprint of Tripleten's DA course.\n",
    "\n",
    "We will bw analizing user's data for the mobile carrier Megaline, in order to train a model that could properly recommend to each customer one of Megaline's new plans: Smart or Ultra.\n",
    "\n",
    "The requested minimum accuracy for this model is **0.75**.\n",
    "\n",
    "For this project we'll be using the following:\n",
    "- Python 3.9.5\n",
    "- Pandas 1.2.4\n",
    "- Sklearn 0.24.1\n",
    "\n",
    "Versions were chosen so they match as closely as possible the versions available on the Tripleten servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e287d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8d1b6",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a940e60",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection\n",
    "\n",
    "Our data is contained in a single table. According to our instructions, the data is already preprocessed. Let's load it and do a quick check to make sure it's ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce4b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"dataset/users_behavior.csv\")      # Local path\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv(\"/datasets/users_behavior.csv\")    # Tripleten server path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0021b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca32978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e82417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490a124",
   "metadata": {},
   "source": [
    "There are no missing values, no negatives, and no absurdly large values. `is_ultra` only contains `0` and `1`.\n",
    "\n",
    "We can begin working with the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd15d6b",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7afd6e",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db775ef8",
   "metadata": {},
   "source": [
    "### Splitting the data into sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72628f",
   "metadata": {},
   "source": [
    "We need to devide our dataset into three sets:\n",
    "\n",
    "- Training set: this will be used to train the model\n",
    "- Validation set: we'll use this set to check the quality of different models, and try to improve them as we adjust hyperparameters.\n",
    "- Test set: this will be the final test for the model, data that has never seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae1f08",
   "metadata": {},
   "source": [
    "We'll distribute the data as follows: \n",
    "- 60% for the training set\n",
    "- 20% for the validation set\n",
    "- 20% for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16996617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First take 20% of the data and save it as the test. df_temp has the other 80%\n",
    "df_temp, df_test = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "# To make the validation set the same size as the test set, we'll take 25% from the temp,\n",
    "# since it only has 80% of the original data. 0.8 * 0.25 = 0.2\n",
    "df_train, df_valid = train_test_split(df_temp, test_size=0.25, random_state=12345)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fa8cd",
   "metadata": {},
   "source": [
    "Let's double check our math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6bc3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1928\n",
      "Validating set size: 643\n",
      "Test set size: 643\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set size: {len(df_train)}')\n",
    "print(f'Validating set size: {len(df_valid)}')\n",
    "print(f'Test set size: {len(df_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445ed783",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(columns='is_ultra')\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop(columns='is_ultra')\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "features_test = df_test.drop(columns='is_ultra')\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a893657",
   "metadata": {},
   "source": [
    "The sets are ready, we can begin training models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55858d0c",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136ad6e",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2868bf9",
   "metadata": {},
   "source": [
    "A decision tree works quite quickly, but with low accuracy. Let's see how it fares in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "625dda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desicion tree training\n",
    "best_tree = None\n",
    "best_accuracy = 0\n",
    "best_depth = 0\n",
    "best_max_features = 0\n",
    "best_leaves = 0\n",
    "\n",
    "max_depth_to_test = 20\n",
    "max_features_to_test = 4\n",
    "max_leaf_samples_to_test = 10\n",
    "\n",
    "for depth in range(1, max_depth_to_test + 1):\n",
    "    for features in range(1, max_features_to_test + 1):\n",
    "        for leaves in range(1, max_leaf_samples_to_test + 1):\n",
    "            model = DecisionTreeClassifier(\n",
    "                max_depth=depth,\n",
    "                min_samples_leaf=leaves,\n",
    "                max_features=features,\n",
    "                random_state=12345)\n",
    "\n",
    "            model.fit(features_train, target_train)\n",
    "            accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_tree = model\n",
    "                best_depth = depth\n",
    "                best_max_features=features\n",
    "                best_leaves = leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee49d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Tree has an accuracy of 0.801\n",
      "\n",
      "The hyperparameters are:\n",
      "depth = 10\n",
      "max_features = 1\n",
      "min_samples_leaf = 9\n"
     ]
    }
   ],
   "source": [
    "# Training results\n",
    "print(f'The best Tree has an accuracy of {best_accuracy:0.3f}\\n')\n",
    "print('The hyperparameters are:')\n",
    "print(f'depth = {best_depth}')\n",
    "print(f'max_features = {best_max_features}')\n",
    "print(f'min_samples_leaf = {best_leaves}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2e5ed",
   "metadata": {},
   "source": [
    "We managed to get a Decision tree with an accuracy score of 0.8. The hyperparameters used are: \n",
    "\n",
    "It's quite promising. But we still have more models to try."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756afd23",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184b81e",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8ce21",
   "metadata": {},
   "source": [
    "Instead of a single tree, we can use several and have them vote. This should improve accuracy, at the expense of speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381bedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest training\n",
    "best_forest = None\n",
    "best_accuracy = 0\n",
    "best_estimators = 0\n",
    "best_depth = 0\n",
    "best_leaves = 0\n",
    "best_features = 0\n",
    "\n",
    "max_estimators_to_test = 100\n",
    "max_depth_to_test = 15\n",
    "max_leaf_samples_to_test = 10\n",
    "max_features_to_test = 4\n",
    "\n",
    "\n",
    "\n",
    "for est in range(9, max_estimators_to_test + 1, 10):\n",
    "    for depth in range(1, max_depth_to_test + 1):\n",
    "        for leaves in range(1, max_leaf_samples_to_test + 1):\n",
    "            for feat in range(1, max_features_to_test + 1):\n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=est,\n",
    "                    max_depth=depth,\n",
    "                    min_samples_leaf=leaves,\n",
    "                    max_features=feat,\n",
    "                    random_state=12345\n",
    "                )\n",
    "\n",
    "                model.fit(features_train, target_train)\n",
    "                accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_forest = model\n",
    "                    best_estimators = est\n",
    "                    best_depth = depth\n",
    "                    best_leaves = leaves\n",
    "                    best_features = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "310e0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest training\n",
    "best_forest = None\n",
    "best_accuracy = 0\n",
    "best_estimators = 0\n",
    "best_depth = 0\n",
    "best_leaves = 0\n",
    "best_features = 0\n",
    "\n",
    "max_estimators_to_test = 250\n",
    "max_depth_to_test = 20\n",
    "max_leaf_samples_to_test = 10\n",
    "max_features_to_test = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd15064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 1, acc = 0.7620528771384136\n",
      "depth = 2, acc = 0.7620528771384136\n",
      "depth = 3, acc = 0.7682737169517885\n",
      "depth = 4, acc = 0.7729393468118196\n",
      "depth = 5, acc = 0.7791601866251944\n",
      "depth = 6, acc = 0.7791601866251944\n",
      "depth = 7, acc = 0.7853810264385692\n",
      "depth = 8, acc = 0.7822706065318819\n",
      "depth = 9, acc = 0.7900466562986003\n",
      "depth = 10, acc = 0.7962674961119751\n",
      "depth = 11, acc = 0.7978227060653188\n",
      "depth = 12, acc = 0.7978227060653188\n",
      "depth = 13, acc = 0.7993779160186625\n",
      "depth = 14, acc = 0.7962674961119751\n",
      "depth = 15, acc = 0.7993779160186625\n",
      "depth = 16, acc = 0.8009331259720062\n",
      "depth = 17, acc = 0.7931570762052877\n",
      "depth = 18, acc = 0.7993779160186625\n",
      "depth = 19, acc = 0.7884914463452566\n",
      "depth = 20, acc = 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "#To improve training speed, we'll first get a good range of depth and estimators\n",
    "# First find a good range for max_depth\n",
    "for depth in range(1, max_depth_to_test + 1):\n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=depth,\n",
    "        random_state=12345\n",
    "    )\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "    print(f'depth = {depth}, acc = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e081f87",
   "metadata": {},
   "source": [
    "The best depth is 16, but we'll try a range around it. From `13 to 18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf1ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 9 acc = 0.7869362363919129\n",
      "n_estimators = 19 acc = 0.7869362363919129\n",
      "n_estimators = 29 acc = 0.7916018662519441\n",
      "n_estimators = 39 acc = 0.7931570762052877\n",
      "n_estimators = 49 acc = 0.7931570762052877\n",
      "n_estimators = 59 acc = 0.7947122861586314\n",
      "n_estimators = 69 acc = 0.7916018662519441\n",
      "n_estimators = 79 acc = 0.7947122861586314\n",
      "n_estimators = 89 acc = 0.7978227060653188\n",
      "n_estimators = 99 acc = 0.8009331259720062\n",
      "n_estimators = 109 acc = 0.7978227060653188\n",
      "n_estimators = 119 acc = 0.7978227060653188\n",
      "n_estimators = 129 acc = 0.7993779160186625\n",
      "n_estimators = 139 acc = 0.7993779160186625\n",
      "n_estimators = 149 acc = 0.7993779160186625\n",
      "n_estimators = 159 acc = 0.7993779160186625\n",
      "n_estimators = 169 acc = 0.8009331259720062\n",
      "n_estimators = 179 acc = 0.7993779160186625\n",
      "n_estimators = 189 acc = 0.8009331259720062\n",
      "n_estimators = 199 acc = 0.8009331259720062\n",
      "n_estimators = 209 acc = 0.8009331259720062\n",
      "n_estimators = 219 acc = 0.7993779160186625\n",
      "n_estimators = 229 acc = 0.7993779160186625\n",
      "n_estimators = 239 acc = 0.7978227060653188\n",
      "n_estimators = 249 acc = 0.7978227060653188\n"
     ]
    }
   ],
   "source": [
    "# Finding a good range for n_estimators\n",
    "for est in range(9, max_estimators_to_test + 1, 10):\n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=16,\n",
    "        n_estimators=est,\n",
    "        random_state=12345\n",
    "    )\n",
    "    model.fit(features_train, target_train)\n",
    "    accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "    print(f'n_estimators = {est} acc = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdd872",
   "metadata": {},
   "source": [
    "We get the best result with 99 estimators, and then with 169, 189, 199 and 209. However, the difference is pretty small. We'll use `99`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d381a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the rest of the hyperparameters\n",
    "for depth in range(13, 19):\n",
    "    for leaves in range(1, max_leaf_samples_to_test + 1):\n",
    "        for feat in range(1, max_features_to_test + 1):\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=99,\n",
    "                max_depth=depth,\n",
    "                min_samples_leaf=leaves,\n",
    "                max_features=feat,\n",
    "                random_state=12345\n",
    "            )\n",
    "\n",
    "            model.fit(features_train, target_train)\n",
    "            accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_forest = model\n",
    "                best_estimators = est\n",
    "                best_depth = depth\n",
    "                best_leaves = leaves\n",
    "                best_features = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b72a2a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Forest has an accuracy of 0.802\n",
      "\n",
      "The hyperparameters are:\n",
      "estimators = 249\n",
      "depth = 15\n",
      "min_sample_leaf = 1\n",
      "max_features = 1\n"
     ]
    }
   ],
   "source": [
    "# Training results\n",
    "print(f'The best Forest has an accuracy of {best_accuracy:0.3f}\\n')\n",
    "print('The hyperparameters are:')\n",
    "print(f'estimators = {best_estimators}')\n",
    "print(f'depth = {best_depth}')\n",
    "print(f'min_sample_leaf = {best_leaves}')\n",
    "print(f'max_features = {best_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004abc7",
   "metadata": {},
   "source": [
    "The random forest model took a very long time to train, and is barely any better than the single decision tree in this case. We managed to get an accuracy of 0.8. \n",
    "\n",
    "Lets try a Logistic Regression model next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3c16d",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397bf2fc",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66075cf",
   "metadata": {},
   "source": [
    "Now we are moving away from trees. This model should have a decent accuracy, and a short training time. Let's see how it performs in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6e352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model training\n",
    "\n",
    "# Many of these combinations will fail, and they will produce a lot of warnings. \n",
    "# We don't care about them right now, so we'll silence them for this cell\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', message='Line Search failed')\n",
    "    warnings.filterwarnings('ignore', message='The line search algorithm did not converge')\n",
    "    warnings.filterwarnings('ignore', message='Rounding errors prevent the line search from converging')\n",
    "    warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "    best_log_regression = None\n",
    "    best_accuracy = 0\n",
    "    best_solver = None\n",
    "    best_penalty = None\n",
    "    best_fit_intercept = None\n",
    "    best_class_weight = None\n",
    "    best_max_iter = None\n",
    "    best_c_value = 0\n",
    "\n",
    "    solver_to_test = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "    penalty_to_test = ['l1', 'l2', 'elasticnet', None]\n",
    "    fit_intercept_to_test = [True, False]\n",
    "    class_weight_to_test = ['balanced', None]\n",
    "    max_iter_to_test = 300\n",
    "    c_values_to_test = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "    for solver in solver_to_test:\n",
    "        for penalty in penalty_to_test:\n",
    "            for fit_intercept in fit_intercept_to_test:\n",
    "                for class_weight in class_weight_to_test:\n",
    "                    for iter in range(100, max_iter_to_test + 1, 20):\n",
    "                        for c in c_values_to_test:\n",
    "                            # Many of these values combinations aren't supported.\n",
    "                            # Those that would throw errors will be skipped. \n",
    "                            try:\n",
    "                                model = LogisticRegression(\n",
    "                                    solver=solver,\n",
    "                                    penalty=penalty,\n",
    "                                    fit_intercept=fit_intercept,\n",
    "                                    class_weight=class_weight,\n",
    "                                    max_iter=iter,\n",
    "                                    C=c,\n",
    "                                    random_state=12345\n",
    "                                )\n",
    "\n",
    "                                model.fit(features_train, target_train)\n",
    "                                accuracy = model.score(features_valid, target_valid)\n",
    "\n",
    "                                if accuracy > best_accuracy:\n",
    "                                    best_accuracy = accuracy\n",
    "                                    best_log_regression = model\n",
    "                                    best_solver = solver\n",
    "                                    best_penalty = penalty\n",
    "                                    best_fit_intercept = fit_intercept\n",
    "                                    best_class_weight = class_weight\n",
    "                                    best_max_iter = iter\n",
    "                                    best_c_value = c\n",
    "                            except ValueError:\n",
    "                                pass # These errors are expected, we'll just ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c9f23ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Logistic regression model has an accuracy of 0.729\n",
      "\n",
      "The hyperparameters are:\n",
      "solver = liblinear\n",
      "penalty = l1\n",
      "fit_intercept = True\n",
      "class_weight = None\n",
      "max_iter = 100\n",
      "c value 0.1\n"
     ]
    }
   ],
   "source": [
    "# Training results\n",
    "print(f'The best Logistic regression model has an accuracy of {best_accuracy:0.3f}\\n')\n",
    "print('The hyperparameters are:')\n",
    "print(f'solver = {best_solver}')\n",
    "print(f'penalty = {best_penalty}')\n",
    "print(f'fit_intercept = {best_fit_intercept}')\n",
    "print(f'class_weight = {best_class_weight}')\n",
    "print(f'max_iter = {best_max_iter}')\n",
    "print(f'c value {best_c_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bde80",
   "metadata": {},
   "source": [
    "The best accuracy we could get from this model is 0.73. It doesn't fit our requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea012a50",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9638c25",
   "metadata": {},
   "source": [
    "### Quality check using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64735018",
   "metadata": {},
   "source": [
    "The best model we got, by a tiny margin, is the Random Forest.\n",
    "\n",
    "Let's see how it performs with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd0b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the test set: 0.798\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = best_forest.score(features_test, target_test)\n",
    "print(f'Accuracy with the test set: {test_accuracy:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0571817",
   "metadata": {},
   "source": [
    "We are above our required accuracy! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762bc7e",
   "metadata": {},
   "source": [
    "Let's check the precision and recall too, to get a better idea on what is our model doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d8a7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.732\n",
      "Recall: 0.531\n"
     ]
    }
   ],
   "source": [
    "test_predictions = best_forest.predict(features_test)\n",
    "print(f'Precision: {precision_score(target_test, test_predictions):0.3f}')\n",
    "print(f'Recall: {recall_score(target_test, test_predictions):0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb4384",
   "metadata": {},
   "source": [
    "When the model predicts an Ultra user, it is 73% correct. But it only picks up on 53% of Ultra users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7472a1b",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf722d9",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94468950",
   "metadata": {},
   "source": [
    "How would we fare if we just assigned one of the plans to everyone, or if we did it randomly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "308e7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3048211508553655\n"
     ]
    }
   ],
   "source": [
    "# Ratio of Ultra users\n",
    "print(df_test['is_ultra'].sum() / df_test['is_ultra'].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeeebdc",
   "metadata": {},
   "source": [
    "About 30% of the clients are using the Ultra plan. \n",
    "\n",
    "If we assign the Smart plan to everyone, we would have an accuracy of 0.7, as that is the proportion of Smart users.\n",
    "\n",
    "If we assign a plan randomly, we would have an accuracy of 0.5, as each case has a 50/50 chance of being correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef82e7",
   "metadata": {},
   "source": [
    "Let's try another approach now. Let's use a DummyClassifier. Our Random Forest should have a greater accuracy than the Dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26710e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strat: most_frequent\n",
      "accuracy: 0.695\n",
      "\n",
      "Strat: prior\n",
      "accuracy: 0.695\n",
      "\n",
      "Strat: stratified\n",
      "accuracy: 0.575\n",
      "\n",
      "Strat: uniform\n",
      "accuracy: 0.490\n",
      "\n",
      "Strat: constant\n",
      "accuracy: 0.695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "strategies_to_test = ['most_frequent', 'prior', 'stratified', 'uniform', 'constant']\n",
    "for strat in strategies_to_test:\n",
    "    dummy = DummyClassifier(\n",
    "        strategy=strat,\n",
    "        constant=0,\n",
    "        random_state=12345\n",
    "    )\n",
    "    dummy.fit(features_test, target_test)\n",
    "    accuracy = dummy.score(features_test, target_test)\n",
    "    print(f'Strat: {strat}\\naccuracy: {accuracy:0.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2e3a1",
   "metadata": {},
   "source": [
    "Since our model's accuracy is 0.798, it is better than chance, and better than every strategy the dummy can use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd547eb",
   "metadata": {},
   "source": [
    "[Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b2f47",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a9ee5",
   "metadata": {},
   "source": [
    "Our task was to develop a model with the highest accuracy possible. The minimum required was 0.75.\n",
    "\n",
    "The Random Forest managed to get an accuracy score of 0.798.\n",
    "\n",
    "The Decision Tree was very close to the Random Forest when tested against the validation set, so if run time is an issue, the tree could be used instead of the Forest, with very similar results but faster execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565459c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
